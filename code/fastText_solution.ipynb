{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'D:\\\\Desktop\\\\MachineLearning\\\\NLP\\\\NLP新闻分类赛'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r'D:\\Desktop\\MachineLearning\\NLP\\NLP新闻分类赛')\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T06:41:52.505816300Z",
     "start_time": "2025-01-18T06:41:52.491782Z"
    }
   },
   "id": "806d072ab603b1c",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-18T06:42:20.840025500Z",
     "start_time": "2025-01-18T06:42:09.892409600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 转换为FastText需要的格式\n",
    "train_df = pd.read_csv('./data/train_set.csv', sep='\\t')\n",
    "test_df = pd.read_csv('./data/test_a.csv', sep='\\t')\n",
    "# train_df['label_ft'] = '__label__' + train_df['label'].astype(str)\n",
    "# train_df[['text', 'label_ft']].to_csv('./preprocess/train_fastText.csv', index=None, header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.train_supervised('./preprocess/train_fastText.csv',\n",
    "                                  lr=0.01,\n",
    "                                  epoch=50,\n",
    "                                  dim=256,\n",
    "                                  ws=5,\n",
    "                                  seed=42,\n",
    "                                  wordNgrams=3,\n",
    "                                  verbose=2,\n",
    "                                  minCount=3,\n",
    "                                  t=1e-4,\n",
    "                                  loss=\"softmax\",)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T06:08:42.471578100Z",
     "start_time": "2025-01-18T05:26:37.620760800Z"
    }
   },
   "id": "5ffc8f7f3c346cec",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save_model('./model/fastText_dim_256.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T06:34:11.178010400Z",
     "start_time": "2025-01-18T06:34:09.740899500Z"
    }
   },
   "id": "9ccdd7256f178b3a",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "89da9ab812d4d753"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model('./model/fastText_dim_256.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T06:43:32.762113600Z",
     "start_time": "2025-01-18T06:43:29.589871600Z"
    }
   },
   "id": "96c8e0a7fbc65db4",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "(('__label__8',), array([1.00001001]))\n"
     ]
    }
   ],
   "source": [
    "# for text in test_df['text']:\n",
    "#     print(type(text))\n",
    "#     print(model.predict(\"aaa\"))\n",
    "#     break;"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T06:43:44.806220400Z",
     "start_time": "2025-01-18T06:43:44.790134500Z"
    }
   },
   "id": "694b9c987b8d804f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# 预测测试集\n",
    "# y_test_pred = []\n",
    "# for text in test_df['text']:\n",
    "#     pred_label = model.predict(text)[0][0].split('__')[-1]\n",
    "#     y_test_pred.append(pred_label)\n",
    "    \n",
    "y_test_pred = [model.predict(text)[0][0].split('__')[-1] for text in test_df['text']]\n",
    "# 将预测结果存储到 test_df 的 'label' 列\n",
    "test_df['label'] = y_test_pred\n",
    "\n",
    "# 保存结果到 CSV 文件\n",
    "test_df['label'].to_csv(\"./result/submission_fastText.csv\", index=False)\n",
    "print(\"Results saved successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T06:44:49.096630200Z",
     "start_time": "2025-01-18T06:44:09.284941400Z"
    }
   },
   "id": "c8f61a6b3d3845eb",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    加载数据\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_data(data, n_folds=5):\n",
    "    \"\"\"\n",
    "    将数据划分为 n_folds 份\n",
    "    \"\"\"\n",
    "    np.random.shuffle(data)\n",
    "    fold_size = len(data) // n_folds\n",
    "    folds = []\n",
    "    for i in range(n_folds):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size if i < n_folds - 1 else len(data)\n",
    "        folds.append(data[start:end])\n",
    "    return folds\n",
    "\n",
    "\n",
    "def train_and_evaluate(folds, n_folds=5):\n",
    "    \"\"\"\n",
    "    进行交叉验证\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for i in range(n_folds):\n",
    "        # 划分训练集和验证集\n",
    "        validation_set = folds[i]\n",
    "        train_set = [item for j, fold in enumerate(folds) if j!= i for item in fold]\n",
    "        \n",
    "        # 将训练集和验证集保存到临时文件\n",
    "        with open('temp_train.txt', 'w') as train_file:\n",
    "            train_file.writelines(train_set)\n",
    "        with open('temp_val.txt', 'w') as val_file:\n",
    "            val_file.writelines(validation_set)\n",
    "        \n",
    "        # 训练模型\n",
    "        model = fasttext.train_supervised('temp_train.txt',\n",
    "                                     lr=0.01,\n",
    "                                     epoch=50,\n",
    "                                     dim=256,\n",
    "                                     ws=5,\n",
    "                                     nthread=16,\n",
    "                                     seed=42,\n",
    "                                     wordNgrams=3,\n",
    "                                     verbose=2,\n",
    "                                     minCount=3,\n",
    "                                     t=1e-4,\n",
    "                                     loss=\"softmax\")\n",
    "        \n",
    "        # 评估模型\n",
    "        result = model.test('temp_val.txt')\n",
    "        precision = result[1]\n",
    "        scores.append(precision)\n",
    "        print(f\"Fold {i + 1} Precision: {precision}\")\n",
    "    \n",
    "    return scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7400563076cde66d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "nlp",
   "language": "python",
   "display_name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
